"""
Vizota AI FastAPI Server
ì´ë¯¸ì§€ íƒœê¹… ë° í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ API ì„œë²„
"""

import os
os.environ["TF_USE_LEGACY_KERAS"] = "1"

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, HttpUrl
from typing import List, Optional
import torch
from transformers import MobileViTFeatureExtractor, MobileViTForImageClassification, pipeline
from PIL import Image
from urllib.request import urlopen
import predict_one_image
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Vizota AI API",
    description="Image Tagging and Quality Assessment API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
if torch.cuda.is_available():
    device = torch.device('cuda')
    device_id = 0
elif torch.backends.mps.is_available():
    device = torch.device('mps')
    device_id = 0
else:
    device = torch.device('cpu')
    device_id = -1

logger.info(f"Using device: {device}")

# ì „ì—­ ë³€ìˆ˜ - ëª¨ë¸ë“¤
feature_extractor = None
model = None
classifier = None
feature_maps = {}
target_layer_name = 'dropout'

# Response Models
class ImageAnalysisResponse(BaseModel):
    tag_name: str
    probability: float
    category: Optional[str] = None
    category_probability: Optional[float] = None
    quality_score: Optional[float] = None
    feature_vector: Optional[List[List[float]]] = None

class HealthResponse(BaseModel):
    status: str
    device: str
    models_loaded: bool

# Feature extraction hook
def get_features(name):
    def hook(model, input, output):
        if isinstance(output, tuple):
            feature_maps[name] = output[0].detach()
        else:
            feature_maps[name] = output.detach()
    return hook

# ëª¨ë¸ ì´ˆê¸°í™”
@app.on_event("startup")
async def load_models():
    global feature_extractor, model, classifier
    
    logger.info("ğŸš€ Loading AI models...")
    
    try:
        # MobileViT ëª¨ë¸ ë¡œë“œ
        feature_extractor = MobileViTFeatureExtractor.from_pretrained("apple/mobilevit-small")
        model = MobileViTForImageClassification.from_pretrained("apple/mobilevit-small")
        model.eval()
        model.to(device)
        
        # Feature extraction hook ì„¤ì •
        try:
            target_layer = dict(model.named_modules())[target_layer_name]
            target_layer.register_forward_hook(get_features(target_layer_name))
            logger.info("âœ… Feature Vector ì¶”ì¶œ ì„¤ì • ì™„ë£Œ")
        except KeyError:
            logger.warning("âš ï¸ Feature Vector ì¶”ì¶œ ì„¤ì • ì‹¤íŒ¨")
        
        # Zero-shot classification ëª¨ë¸ ë¡œë“œ
        classifier = pipeline(
            "zero-shot-classification",
            model="facebook/bart-large-mnli",
            device=device_id
        )
        
        logger.info(f"âœ… All models loaded successfully on {device}")
        
    except Exception as e:
        logger.error(f"âŒ Error loading models: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    logger.info("ğŸ‘‹ Shutting down Vizota AI API Server...")

# Health Check
@app.get("/", response_model=HealthResponse)
async def root():
    return {
        "status": "healthy",
        "device": str(device),
        "models_loaded": model is not None and classifier is not None
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    return {
        "status": "healthy",
        "device": str(device),
        "models_loaded": model is not None and classifier is not None
    }

# ì´ë¯¸ì§€ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/analyze-image", response_model=ImageAnalysisResponse)
async def analyze_image(
    image_url: str = Query(..., description="S3 image URL to analyze"),
    candidate_labels: Optional[List[str]] = Query(
        None,
        description="Candidate labels for hierarchical classification (e.g., album names)"
    )
):
    """
    S3 ì´ë¯¸ì§€ URLì„ ë°›ì•„ì„œ íƒœê·¸, í’ˆì§ˆ ì ìˆ˜, ì¶”ì²œ ìƒìœ„ íƒœê·¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    - **image_url**: ë¶„ì„í•  ì´ë¯¸ì§€ì˜ S3 URL
    - **candidate_labels**: (ì„ íƒ) ê³„ì¸µì  ë¶„ë¥˜ë¥¼ ìœ„í•œ í›„ë³´ ë ˆì´ë¸” ëª©ë¡ (ì•¨ë²” ì´ë¦„ ë“±)
    
    Returns:
        - tag_name: ì´ë¯¸ì§€ ë¶„ë¥˜ëª…
        - probability: ë¶„ë¥˜ í™•ë¥  (%)
        - category: ì¶”ì²œ ìƒìœ„ íƒœê·¸ (candidate_labels ì œê³µ ì‹œ)
        - category_probability: ì¶”ì²œ íƒœê·¸ í™•ë¥  (%)
        - quality_score: ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ (0-1)
        - feature_vector: ì¶”ì¶œëœ feature vector (2D array)
    """
    try:
        # ëª¨ë¸ ë¡œë“œ í™•ì¸
        if model is None or classifier is None:
            raise HTTPException(status_code=503, detail="Models not loaded yet")
        
        logger.info(f"Analyzing image: {image_url}")
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (í•œ ë²ˆë§Œ)
        try:
            image = Image.open(urlopen(image_url)).convert('RGB')
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Failed to load image: {str(e)}")
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° íƒœê¹…
        inputs = feature_extractor(images=image, return_tensors="pt").to(device)
        
        with torch.no_grad():
            # íƒœê·¸ ì˜ˆì¸¡
            outputs = model(**inputs)
            logits = outputs.logits
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (PIL Image ê°ì²´ ì „ë‹¬)
            try:
                quality_score = predict_one_image.main(image)
                # tensorë¥¼ floatë¡œ ë³€í™˜
                if torch.is_tensor(quality_score):
                    quality_score = quality_score.item()
            except Exception as e:
                logger.warning(f"Quality score calculation failed: {e}")
                quality_score = None
        
        # Top prediction ì¶”ì¶œ
        top_probability, top_class_index = torch.topk(logits.softmax(dim=1) * 100, k=1)
        
        class_name = model.config.id2label[top_class_index[0][0].item()]
        probability = top_probability[0][0].item()
        
        # Feature vector ì¶”ì¶œ
        feature_vector = None
        if target_layer_name in feature_maps:
            extracted_features = feature_maps[target_layer_name]
            # tensorë¥¼ listë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡)
            feature_vector = extracted_features.cpu().numpy().tolist()
            logger.info(f"Feature vector size: {extracted_features.size()}")
        
        # ê³„ì¸µì  ë¶„ë¥˜ (candidate_labelsê°€ ì œê³µëœ ê²½ìš°)
        recommended_tag = None
        recommended_tag_prob = None
        
        if candidate_labels and len(candidate_labels) > 0:
            try:
                hierar = classifier(class_name, candidate_labels, multi_label=True)
                recommended_tag = hierar['labels'][0]
                recommended_tag_prob = hierar['scores'][0] * 100
                logger.info(f"Recommended tag: {recommended_tag} ({recommended_tag_prob:.2f}%)")
            except Exception as e:
                logger.warning(f"Hierarchical classification failed: {e}")
        
        response = ImageAnalysisResponse(
            tag_name=class_name,
            probability=round(probability, 2),
            category=recommended_tag,
            category_probability=round(recommended_tag_prob, 2) if recommended_tag_prob else None,
            quality_score=round(quality_score, 4) if quality_score else None,
            feature_vector=feature_vector
        )
        
        logger.info(f"Analysis complete: {class_name} ({probability:.2f}%)")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error analyzing image: {e}")
        raise HTTPException(status_code=500, detail=f"Error processing image: {str(e)}")

# í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/test")
async def test():
    """
    í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ - ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ ë¶„ì„ í…ŒìŠ¤íŠ¸
    """
    test_url = "https://d206helh22e0a3.cloudfront.net/images/brow/combo/combo.png"
    test_labels = ["travel", "food", "landscape", "portrait"]
    
    return await analyze_image(image_url=test_url, candidate_labels=test_labels)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001, log_level="info")
